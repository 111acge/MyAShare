{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####################\n",
    "### 导入部分 ###\n",
    "#####################\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta"
   ],
   "id": "7917a789c0a5f179",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####################\n",
    "###  公司基本信息  ###\n",
    "#####################\n",
    "def get_company_info(code):\n",
    "    # 获取市场前缀\n",
    "    symbol = f\"{code}\"\n",
    "    info_dict = {}\n",
    "\n",
    "    try:\n",
    "        # 基础信息\n",
    "        base_info = ak.stock_individual_info_em(symbol=symbol)\n",
    "        info_dict['股票简称'] = base_info.loc[base_info['item'] == '股票简称', 'value'].values[0]\n",
    "        info_dict['行业'] = base_info.loc[base_info['item'] == '行业', 'value'].values[0]\n",
    "        info_dict['上市时间'] = base_info.loc[base_info['item'] == '上市时间', 'value'].values[0]\n",
    "    except Exception as e:\n",
    "        print(f\"基础信息获取失败: {str(e)}\")\n",
    "        info_dict.update({'股票简称': '未知', '行业': '未知', '上市时间': '未知'})\n",
    "\n",
    "    try:\n",
    "        # 发行信息\n",
    "        stock_ipo_info_df = ak.stock_ipo_info(stock=symbol)\n",
    "        if not stock_ipo_info_df.empty:\n",
    "            info_dict['发行价'] = stock_ipo_info_df.loc[stock_ipo_info_df['item'] == '发行价(元)', 'value'].values[0]\n",
    "        else:\n",
    "            info_dict['发行价'] = '暂无数据'\n",
    "    except Exception as e:\n",
    "        print(f\"发行价获取失败: {str(e)}\")\n",
    "        info_dict['发行价'] = '暂无数据'\n",
    "\n",
    "    try:\n",
    "        # 分红信息\n",
    "        stock_history_dividend_df = ak.stock_history_dividend()\n",
    "        dividend_info = stock_history_dividend_df[stock_history_dividend_df['代码'] == code]\n",
    "        # 如果找到记录，获取分红次数列的值；如果没找到记录，则为0\n",
    "        info_dict['分红次数'] = dividend_info['分红次数'].iloc[0] if not dividend_info.empty else 0\n",
    "    except Exception as e:\n",
    "        print(f\"分红信息获取失败: {str(e)}\")\n",
    "        info_dict['分红次数'] = 0\n",
    "\n",
    "    try:\n",
    "        # 机构参与度\n",
    "        jg_info = ak.stock_comment_detail_zlkp_jgcyd_em(symbol=symbol)\n",
    "        info_dict['机构参与度'] = f\"{jg_info['机构参与度'].values[0]}%\"\n",
    "    except Exception as e:\n",
    "        print(f\"机构参与度获取失败: {str(e)}\")\n",
    "        info_dict['机构参与度'] = '暂无数据'\n",
    "\n",
    "    try:\n",
    "        # 市场成本\n",
    "        cost_info = ak.stock_comment_detail_scrd_cost_em(symbol=symbol)\n",
    "        info_dict['市场成本'] = f\"{cost_info['市场成本'].values[0]}元\"\n",
    "    except Exception as e:\n",
    "        print(f\"市场成本获取失败: {str(e)}\")\n",
    "        info_dict['市场成本'] = '暂无数据'\n",
    "\n",
    "    # 格式化输出\n",
    "    print(f\"\\n===== {code} 公司基本信息 =====\")\n",
    "    print(f\"股票简称：{info_dict['股票简称']}\")\n",
    "    print(f\"所属行业：{info_dict['行业']}\")\n",
    "    print(f\"上市时间：{info_dict['上市时间']}\")\n",
    "    print(f\"发行价格：{info_dict['发行价']}\")\n",
    "    print(f\"分红次数：{info_dict['分红次数']}次\")\n",
    "    print(f\"机构参与：{info_dict['机构参与度']}\")\n",
    "    print(f\"成本均价：{info_dict['市场成本']}\")\n",
    "\n",
    "    return info_dict\n",
    "\n",
    "\n",
    "stock_code = input(\"请输入6位股票代码: \")\n",
    "company_info = get_company_info(stock_code)"
   ],
   "id": "34d9722a674bcce3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####################\n",
    "###  获取历史数据   ###\n",
    "#####################\n",
    "def get_history_data(code):\n",
    "    symbol = f\"{code}\"\n",
    "    days = 365\n",
    "    end_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    start_date = (datetime.now() - timedelta(days)).strftime(\"%Y%m%d\")\n",
    "    df = ak.stock_zh_a_hist(symbol=symbol, period=\"daily\", start_date=start_date, end_date=end_date, adjust=\"qfq\")\n",
    "    print(f\"历史{days}天数据获取完成，共获取{len(df)}条记录\")\n",
    "    return df\n",
    "\n",
    "\n",
    "history_df = get_history_data(stock_code)"
   ],
   "id": "ac4ad8a7fa934a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####################\n",
    "###   获取筹码分布  ###\n",
    "#####################\n",
    "def get_chip_distribution(code):\n",
    "    symbol = f\"{code}\"\n",
    "    df = ak.stock_cyq_em(symbol=symbol)\n",
    "    latest_chip = df.iloc[-1].to_dict()\n",
    "    print(\n",
    "        f\"最新交易日筹码分布：获利比例={latest_chip['获利比例'] * 100:.2f}% 70集中度={(latest_chip['70集中度'] * 100):.2f}%\")\n",
    "    return latest_chip\n",
    "\n",
    "\n",
    "get_chip_distribution(stock_code)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:41:22.537687Z",
     "start_time": "2025-01-27T15:41:22.529744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#####################\n",
    "###  BBIBOLL计算   ###\n",
    "#####################\n",
    "def calculate_bbiboll(df):\n",
    "    df['MA3'] = df['收盘'].rolling(3).mean()\n",
    "    df['MA6'] = df['收盘'].rolling(6).mean()\n",
    "    df['MA12'] = df['收盘'].rolling(12).mean()\n",
    "    df['MA24'] = df['收盘'].rolling(24).mean()\n",
    "\n",
    "    df['BBIBOLL'] = (df['MA3'] + df['MA6'] + df['MA12'] + df['MA24']) / 4\n",
    "    df['UPPER'] = df['BBIBOLL'] + 2 * df['BBIBOLL'].rolling(11).std()\n",
    "    df['LOWER'] = df['BBIBOLL'] - 2 * df['BBIBOLL'].rolling(11).std()\n",
    "\n",
    "    latest = df.iloc[-1][['BBIBOLL', 'UPPER', 'LOWER']].to_dict()\n",
    "    print(f\"最新BBIBOLL值: mid={latest['BBIBOLL']:.2f} upper={latest['UPPER']:.2f} lower={latest['LOWER']:.2f}\")\n",
    "    return latest\n",
    "\n",
    "\n",
    "calculate_bbiboll(history_df)"
   ],
   "id": "5b7dc2df4b122623",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最新BBIBOLL值: mid=23.33 upper=23.75 lower=22.90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BBIBOLL': 23.32645833333333,\n",
       " 'UPPER': 23.748683857372665,\n",
       " 'LOWER': 22.904232809293998}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:41:00.782299Z",
     "start_time": "2025-01-27T15:22:04.212065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "class EnhancedLSTM(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 双向LSTM层\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        # 注意力机制\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "        # 输出层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, hidden_size),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "\n",
    "        # LSTM输出\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # 注意力权重\n",
    "        attn_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)\n",
    "\n",
    "        # 输出层\n",
    "        out = self.fc(context)\n",
    "        return out\n",
    "\n",
    "def enhanced_predict(df, target_col='收盘'):\n",
    "    \"\"\"综合多特征、参数搜索和高级LSTM结构的增强预测函数\"\"\"\n",
    "    # 准备多特征数据\n",
    "    feature_cols = ['开盘', '最高', '最低', '收盘', '成交量']\n",
    "    target_idx = feature_cols.index(target_col)\n",
    "\n",
    "    # 数据标准化\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "    # 参数网格配置\n",
    "    param_grid = {\n",
    "        'hidden_size': [64, 128],\n",
    "        'num_layers': [2, 3],\n",
    "        'dropout': [0.2, 0.3],\n",
    "        'look_back': [30, 60],\n",
    "        'learning_rate': [0.001, 0.0005],\n",
    "        'epochs': [150],\n",
    "        'patience': [15]\n",
    "    }\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_params = {}\n",
    "    best_model_state = None\n",
    "    best_scaler = None\n",
    "    best_look_back = 0\n",
    "    best_predictions = None\n",
    "    best_actuals = None\n",
    "\n",
    "    # 参数搜索\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        look_back = params['look_back']\n",
    "\n",
    "        # 创建序列数据集\n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled_data) - look_back):\n",
    "            X.append(scaled_data[i:i+look_back])\n",
    "            y.append(scaled_data[i+look_back, target_idx])\n",
    "\n",
    "        if len(X) < 10:  # 跳过数据量不足的参数组合\n",
    "            continue\n",
    "\n",
    "        X = torch.FloatTensor(X)\n",
    "        y = torch.FloatTensor(y).view(-1, 1)\n",
    "\n",
    "        # 模型初始化\n",
    "        model = EnhancedLSTM(\n",
    "            input_size=len(feature_cols),\n",
    "            hidden_size=params['hidden_size'],\n",
    "            num_layers=params['num_layers'],\n",
    "            dropout=params['dropout']\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # 训练循环\n",
    "        best_train_loss = float('inf')\n",
    "        stop_counter = 0\n",
    "\n",
    "        for epoch in range(params['epochs']):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # 早停机制\n",
    "            if loss.item() < best_train_loss:\n",
    "                best_train_loss = loss.item()\n",
    "                stop_counter = 0\n",
    "            else:\n",
    "                stop_counter += 1\n",
    "                if stop_counter >= params['patience']:\n",
    "                    break\n",
    "\n",
    "        # 评估模型\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X)\n",
    "            n_samples = len(preds)\n",
    "\n",
    "            # 反标准化处理\n",
    "            dummy_preds = np.zeros((n_samples, len(feature_cols)))\n",
    "            dummy_preds[:, target_idx] = preds.numpy().flatten()\n",
    "            preds_denorm = scaler.inverse_transform(dummy_preds)[:, target_idx]\n",
    "\n",
    "            dummy_y = np.zeros((n_samples, len(feature_cols)))\n",
    "            dummy_y[:, target_idx] = y.numpy().flatten()\n",
    "            y_denorm = scaler.inverse_transform(dummy_y)[:, target_idx]\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_denorm, preds_denorm))\n",
    "\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_params = params\n",
    "                best_model_state = model.state_dict()\n",
    "                best_scaler = scaler\n",
    "                best_look_back = look_back\n",
    "                best_predictions = preds_denorm\n",
    "                best_actuals = y_denorm\n",
    "\n",
    "    # 最终预测\n",
    "    final_model = EnhancedLSTM(\n",
    "        input_size=len(feature_cols),\n",
    "        hidden_size=best_params['hidden_size'],\n",
    "        num_layers=best_params['num_layers'],\n",
    "        dropout=best_params['dropout']\n",
    "    )\n",
    "    final_model.load_state_dict(best_model_state)\n",
    "    final_model.eval()\n",
    "\n",
    "    last_sequence = scaled_data[-best_look_back:]\n",
    "    input_tensor = torch.FloatTensor(last_sequence).view(1, best_look_back, -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_pred_scaled = final_model(input_tensor).item()\n",
    "        dummy_next = np.zeros((1, len(feature_cols)))\n",
    "        dummy_next[0, target_idx] = next_pred_scaled\n",
    "        next_pred = best_scaler.inverse_transform(dummy_next)[0, target_idx]\n",
    "\n",
    "    # 输出结果\n",
    "    print(f\"\\n{target_col}价预测最佳参数: {best_params}\")\n",
    "    print(f\"训练集RMSE: {best_rmse:.2f}\")\n",
    "    print(f\"实际值={best_actuals[-1]:.2f} 预测值={best_predictions[-1]:.2f} (最新数据点)\")\n",
    "    print(f\"预测下一个交易日的{target_col}价可能为：{next_pred:.2f} 元\")\n",
    "\n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'rmse': best_rmse,\n",
    "        'last_actual': best_actuals[-1],\n",
    "        'last_pred': best_predictions[-1],\n",
    "        'next_pred': next_pred\n",
    "    }\n",
    "\n",
    "# 执行预测\n",
    "print(\"\\n增强版多特征LSTM预测结果：\")\n",
    "for col in ['开盘', '收盘', '最低', '最高']:\n",
    "    enhanced_predict(history_df, col)"
   ],
   "id": "58874e9a8147b068",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "增强版多特征LSTM预测结果：\n",
      "\n",
      "开盘价预测最佳参数: {'dropout': 0.2, 'epochs': 150, 'hidden_size': 128, 'learning_rate': 0.001, 'look_back': 30, 'num_layers': 2, 'patience': 15}\n",
      "训练集RMSE: 0.44\n",
      "实际值=23.33 预测值=23.40 (最新数据点)\n",
      "预测下一个交易日的开盘价可能为：23.33 元\n",
      "\n",
      "收盘价预测最佳参数: {'dropout': 0.3, 'epochs': 150, 'hidden_size': 128, 'learning_rate': 0.001, 'look_back': 60, 'num_layers': 3, 'patience': 15}\n",
      "训练集RMSE: 0.49\n",
      "实际值=23.08 预测值=23.28 (最新数据点)\n",
      "预测下一个交易日的收盘价可能为：23.27 元\n",
      "\n",
      "最低价预测最佳参数: {'dropout': 0.2, 'epochs': 150, 'hidden_size': 128, 'learning_rate': 0.001, 'look_back': 60, 'num_layers': 3, 'patience': 15}\n",
      "训练集RMSE: 0.38\n",
      "实际值=23.08 预测值=22.94 (最新数据点)\n",
      "预测下一个交易日的最低价可能为：22.92 元\n",
      "\n",
      "最高价预测最佳参数: {'dropout': 0.2, 'epochs': 150, 'hidden_size': 128, 'learning_rate': 0.001, 'look_back': 60, 'num_layers': 3, 'patience': 15}\n",
      "训练集RMSE: 0.49\n",
      "实际值=23.54 预测值=23.59 (最新数据点)\n",
      "预测下一个交易日的最高价可能为：23.50 元\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6de3caa05a0de851"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
